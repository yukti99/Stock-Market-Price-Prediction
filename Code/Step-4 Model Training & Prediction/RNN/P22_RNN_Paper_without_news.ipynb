{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P22_RNN_Paper_without_news.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "79ZSnfqqNnyF"
      },
      "source": [
        "# Importing Important libraries \n",
        "\n",
        "# For data cleaning and visualization\n",
        "import math\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "from datetime import date, datetime, timedelta\n",
        "\n",
        "\n",
        "# For model\n",
        "from numpy import newaxis\n",
        "import keras\n",
        "from keras import optimizers, callbacks\n",
        "from keras.layers import InputLayer, Input, Masking, Dense, Activation, Dropout, LSTM\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import optimizers, callbacks\n",
        "\n",
        "from keras.layers import Dense, SimpleRNN, GRU\n",
        "from keras.optimizers import SGD\n",
        "\n",
        "\n",
        "# For saving the model\n",
        "import pickle\n",
        "\n",
        "# For Prediction \n",
        "from numpy import newaxis\n",
        "\n",
        "# For model Evaluation\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# For Plotting \n",
        "import matplotlib.pyplot as plt\n",
        "from pylab import rcParams "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8aESvUOnG0d"
      },
      "source": [
        "def create_windows(data, data_len, sequence_len=10):\n",
        "  data_windows = []\n",
        "  for i in range(data_len - sequence_len):\n",
        "    data_windows.append(data[i : i+sequence_len])\n",
        "\n",
        "  # set the type of training data     \n",
        "  data_windows = np.array(data_windows).astype(float)\n",
        "  return (data_windows)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEBge57wnJNm"
      },
      "source": [
        "def Normalize_data(data_windows):\n",
        "  # number of windows formed \n",
        "  windows_no = data_windows.shape[0]\n",
        "  cols_no = data_windows.shape[2]\n",
        "\n",
        "  # initializing list to store normalized data\n",
        "  normalized_data = []\n",
        "  record_min=[]\n",
        "  record_max=[]\n",
        "\n",
        "  # normalizing begins\n",
        "  for win_index in range(windows_no):\n",
        "    normalized_window = []\n",
        "\n",
        "    for col_index in range(0,1):\n",
        "      # temporary column \n",
        "      t_col = data_windows[win_index, :, col_index]\n",
        "      t_min = min(t_col)\n",
        "      if (col_index == 0):\n",
        "        record_min.append(t_min)\n",
        "      t_col = t_col - t_min      \n",
        "      t_max = max(t_col)\n",
        "      if (col_index == 0):\n",
        "        record_max.append(t_max)\n",
        "      t_col = t_col/t_max\n",
        "      normalized_window.append(t_col)\n",
        "    \n",
        "    for col_index in range(1,  cols_no):\n",
        "      t_col = data_windows[win_index, :, col_index]\n",
        "      normalized_window.append(t_col)\n",
        "\n",
        "    normalized_window = np.array(normalized_window).T\n",
        "    normalized_data.append(normalized_window)\n",
        "\n",
        "  normalized_data=np.array(normalized_data)\n",
        "  return (normalized_data, record_max, record_min)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwFA30a3nLDy"
      },
      "source": [
        "def plot_training_loss(model_hist):\n",
        "  # plotting the lose curve during model training\n",
        "  plt.plot(model_hist.history['loss'])\n",
        "  plt.title('Training Model loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['train'],loc='upper left')\n",
        "  plt.show()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybsRiIrBnM5h"
      },
      "source": [
        "def Model_Evaluation(actual_prices, predicted_prices):\n",
        "  # Mean Absolute Error \n",
        "  MAE = metrics.mean_absolute_error(actual_prices, predicted_prices)\n",
        "  # Mean Squared Error\n",
        "  MSE = metrics.mean_squared_error(actual_prices, predicted_prices)\n",
        "  # Root Mean Squared Error\n",
        "  RMSE = np.sqrt(metrics.mean_squared_error(actual_prices, predicted_prices))\n",
        "\n",
        "  # Mean Absolute Percentage Error in degrees\n",
        "  errors = abs(actual_prices - predicted_prices)\n",
        "  MAPE = 100 * (errors /actual_prices)\n",
        "\n",
        "  # Model Accuracy\n",
        "  Accuracy = 100 - np.mean(MAPE)\n",
        "  return (Accuracy, MAE, MSE, RMSE)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyKebkzQTjRn"
      },
      "source": [
        "def without_news(df):\n",
        "  len_df = df.shape[0]\n",
        "  # Data Preprocessing\n",
        "  # splitting training and testing data\n",
        "  cols = ['Adj Close']\n",
        "  cols2 = ['date']\n",
        "  split = 0.85\n",
        "  i_split = int(len(df) * split)\n",
        "  data_train = df.get(cols).values[:i_split]\n",
        "  data_test  = df.get(cols).values[i_split:]\n",
        "  data_test2  = df.get(cols2).values[i_split:]\n",
        "\n",
        "  len_train  = len(data_train)\n",
        "  len_test   = len(data_test)\n",
        "  len_train_windows = None\n",
        "  # Creating Windows for Test Data\n",
        "  sequence_length=10\n",
        "  data_windows_test = create_windows(data_test,len(data_test),sequence_length)\n",
        "  # get original y_test\n",
        "  y_test_original = data_windows_test[:, -1, [0]]\n",
        "  print('y_test_original.shape',y_test_original.shape)\n",
        "\n",
        "  # Normalization of Test Data\n",
        "  normalized_data_test, record_max_test, record_min_test = Normalize_data(data_windows_test)\n",
        "\n",
        "  x_test = normalized_data_test[:, :-1]\n",
        "  y_test = normalized_data_test[:, -1,[0]]\n",
        "\n",
        "  # Train Data preparation\n",
        "  data_windows = create_windows(data_train,len(data_train),sequence_length)\n",
        "  normalized_data_train,rmax_train, rmin_train = Normalize_data(data_windows)\n",
        "\n",
        "  x_train = normalized_data_train[:, :-1]\n",
        "  y_train = normalized_data_train[:, -1,[0]]\n",
        "\n",
        "  input_dim=x_train.shape[2] #2\n",
        "  input_timesteps=x_train.shape[1] #9\n",
        "\n",
        "  # Simple RNN model\n",
        "  model = Sequential()\n",
        "  model.add(SimpleRNN(units = 60, activation = 'relu',return_sequences = True,input_shape=(input_timesteps, input_dim)))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(SimpleRNN(units = 60,activation = 'relu', return_sequences = True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(SimpleRNN(units = 80, activation = 'relu',return_sequences = True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(SimpleRNN(units = 120,activation = 'relu', return_sequences = True))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(units = 1))\n",
        "  model.compile(optimizer='adam', loss = 'mean_squared_error', metrics=['mean_squared_error'])\n",
        "  hist = model.fit(x_train, y_train, epochs=10, batch_size=32)\n",
        "\n",
        "  plot_training_loss(hist)\n",
        " \n",
        "\n",
        "  # Prediction of Test Data using the Training Model\n",
        "  # Using the trained model for prediction and check the performance metrics\n",
        "  train_predict = model.predict(x_train)\n",
        "  test_predict = model.predict(x_test)\n",
        "  # Multi-sequence Prediction\n",
        "  # predicting x_test\n",
        "  prediction_len = 1\n",
        "  # x_test needs to be predicted \n",
        "  data = x_test\n",
        "  predicted_vals = []\n",
        "  window_size = sequence_length\n",
        "  pre_win_no = int(len(data)/prediction_len)\n",
        "  for i in range(pre_win_no):\n",
        "    # access x_test window by window\n",
        "    curr_frame = data[i*prediction_len]\n",
        "    pred = []\n",
        "    for j in range(prediction_len):\n",
        "      # increase the dimension of current frame by one using newaxis, so that it can be fed to model for prediction\n",
        "      model_predict = model.predict(curr_frame[newaxis,:,:])[0]\n",
        "      pred.append(model_predict)\n",
        "      # shift the current frame forward\n",
        "      curr_frame = curr_frame[1:]\n",
        "      # insert the currently predicted value in the frame\n",
        "      # add the new predicted value at the end of window frame \n",
        "      curr_frame = np.insert(curr_frame, [window_size-2], pred[-1], axis=0)\n",
        "    predicted_vals.append(pred)\n",
        "\n",
        "  # Denormalizing the Prediction Results to get Predicted Adj Close Price\n",
        "\n",
        "  pred_prices = []\n",
        "  len_pre_win = int(len(data)/prediction_len)\n",
        "  cnt=0\n",
        "  for i in range(0,len_pre_win):\n",
        "      for j in range(0,prediction_len):\n",
        "        pred_prices.append(predicted_vals[i][j][0]*record_max_test[cnt]+record_min_test[cnt])\n",
        "        cnt = cnt+1\n",
        "\n",
        "\n",
        "  # Comparing Actual and Predicted Prices\n",
        "  actual_prices = []\n",
        "  for i in y_test_original.tolist():\n",
        "    actual_prices.append(i[0])\n",
        "  dates = []\n",
        "  for i in data_test2.tolist():\n",
        "    dates.append(i[0])\n",
        "  dates = dates[len(dates)-len(actual_prices):]\n",
        "  res = { 'date':dates,\n",
        "        'Actual': actual_prices,\n",
        "        'Predicted': pred_prices\n",
        "        }\n",
        "  df_compare = pd.DataFrame(res,columns = ['date','Actual','Predicted'])\n",
        "  print(df_compare)\n",
        " \n",
        "  # Performance Evaluation\n",
        "  actual_prices = df_compare['Actual']\n",
        "  predicted_prices = df_compare['Predicted']  \n",
        "\n",
        "  Accuracy, MAE, MSE, RMSE = Model_Evaluation(actual_prices, predicted_prices)\n",
        "  print(\"\\n-----Model Evaluation-----------------------------------------------------\\n\")\n",
        "  print(\"LSTM Model Loss = \", model.evaluate(x_test, y_test, verbose = 2))\n",
        "  print(\"Model Accuracy = \", Accuracy)\n",
        "  print(\"Mean Absolute Error = \", MAE,\" degrees\")\n",
        "  print(\"Mean Squared Error = \", MSE)\n",
        "  print(\"Root Mean Squared Error = \", RMSE)\n",
        "  print(\"\\n--------------------------------------------------------------------------\\n\")\n",
        "\n",
        "\n",
        "  return (hist, model, df_compare, Accuracy, MAE, MSE, RMSE)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "SeD6z_KOTphw",
        "outputId": "44801fbe-1dca-49f2-87f1-d3f7735bcae0"
      },
      "source": [
        "df_name = \"source_price.csv\"\n",
        "df = pd.read_csv(df_name, index_col=0)\n",
        "df['date'] = df.index\n",
        "df = df.reset_index(drop=True)\n",
        "df"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>wsj_mean_compound</th>\n",
              "      <th>cnbc_mean_compound</th>\n",
              "      <th>fortune_mean_compound</th>\n",
              "      <th>reuters_mean_compound</th>\n",
              "      <th>Adj Close</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.296000</td>\n",
              "      <td>-0.136600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2636.979980</td>\n",
              "      <td>2017/12/7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.242300</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2651.500000</td>\n",
              "      <td>2017/12/8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2659.989990</td>\n",
              "      <td>2017/12/11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2664.110107</td>\n",
              "      <td>2017/12/12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2662.850098</td>\n",
              "      <td>2017/12/13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>0.030290</td>\n",
              "      <td>0.047433</td>\n",
              "      <td>0.011550</td>\n",
              "      <td>-0.025190</td>\n",
              "      <td>2721.330078</td>\n",
              "      <td>2018/5/25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>-0.052796</td>\n",
              "      <td>0.070442</td>\n",
              "      <td>-0.025721</td>\n",
              "      <td>-0.035568</td>\n",
              "      <td>2689.860107</td>\n",
              "      <td>2018/5/29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>-0.017367</td>\n",
              "      <td>0.038119</td>\n",
              "      <td>-0.076965</td>\n",
              "      <td>-0.063177</td>\n",
              "      <td>2724.010010</td>\n",
              "      <td>2018/5/30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>-0.018636</td>\n",
              "      <td>0.057371</td>\n",
              "      <td>-0.064138</td>\n",
              "      <td>-0.025489</td>\n",
              "      <td>2705.270020</td>\n",
              "      <td>2018/5/31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.061150</td>\n",
              "      <td>0.361200</td>\n",
              "      <td>-0.004489</td>\n",
              "      <td>2734.620117</td>\n",
              "      <td>2018/6/1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     wsj_mean_compound  cnbc_mean_compound  ...    Adj Close        date\n",
              "0             0.296000           -0.136600  ...  2636.979980   2017/12/7\n",
              "1             0.000000            0.000000  ...  2651.500000   2017/12/8\n",
              "2             0.000000            0.000000  ...  2659.989990  2017/12/11\n",
              "3             0.000000            0.000000  ...  2664.110107  2017/12/12\n",
              "4             0.000000            0.000000  ...  2662.850098  2017/12/13\n",
              "..                 ...                 ...  ...          ...         ...\n",
              "116           0.030290            0.047433  ...  2721.330078   2018/5/25\n",
              "117          -0.052796            0.070442  ...  2689.860107   2018/5/29\n",
              "118          -0.017367            0.038119  ...  2724.010010   2018/5/30\n",
              "119          -0.018636            0.057371  ...  2705.270020   2018/5/31\n",
              "120           0.000000           -0.061150  ...  2734.620117    2018/6/1\n",
              "\n",
              "[121 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPm0_b06Tq4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "183e3032-6cb4-4db9-9ec0-a5151ae962ff"
      },
      "source": [
        "hist, model, df_compare, Accuracy, MAE, MSE, RMSE = without_news(df)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_test_original.shape (9, 1)\n",
            "Epoch 1/10\n",
            "3/3 [==============================] - 3s 16ms/step - loss: 0.3574 - mean_squared_error: 0.3574\n",
            "Epoch 2/10\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.2816 - mean_squared_error: 0.2816\n",
            "Epoch 3/10\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2626 - mean_squared_error: 0.2626\n",
            "Epoch 4/10\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2248 - mean_squared_error: 0.2248\n",
            "Epoch 5/10\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.2085 - mean_squared_error: 0.2085\n",
            "Epoch 6/10\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1758 - mean_squared_error: 0.1758\n",
            "Epoch 7/10\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1702 - mean_squared_error: 0.1702\n",
            "Epoch 8/10\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 0.1611 - mean_squared_error: 0.1611\n",
            "Epoch 9/10\n",
            "3/3 [==============================] - 0s 14ms/step - loss: 0.1452 - mean_squared_error: 0.1452\n",
            "Epoch 10/10\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.1522 - mean_squared_error: 0.1522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "        date       Actual    Predicted\n",
            "0  2018/5/21  2712.969971  [2694.9062]\n",
            "1  2018/5/22  2733.010010   [2696.152]\n",
            "2  2018/5/23  2724.439941  [2711.7605]\n",
            "3  2018/5/24  2733.290039  [2720.9536]\n",
            "4  2018/5/25  2727.760010  [2721.7825]\n",
            "5  2018/5/29  2721.330078  [2722.2058]\n",
            "6  2018/5/30  2689.860107  [2708.4922]\n",
            "7  2018/5/31  2724.010010  [2710.4497]\n",
            "8   2018/6/1  2705.270020  [2710.0364]\n",
            "\n",
            "-----Model Evaluation-----------------------------------------------------\n",
            "\n",
            "1/1 - 1s - loss: 0.1136 - mean_squared_error: 0.1136\n",
            "LSTM Model Loss =  [0.11363237351179123, 0.11363237351179123]\n",
            "Model Accuracy =  [99.49454]\n",
            "Mean Absolute Error =  13.74994581423612  degrees\n",
            "Mean Squared Error =  287.55683670574274\n",
            "Root Mean Squared Error =  16.95750089800212\n",
            "\n",
            "--------------------------------------------------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}